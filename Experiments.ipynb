{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Jumping Knowledge Networks on Citeseer and Cora\n",
    "Here I try to replicate the evaluation of JK Networks described in the [Xu et al.](https://arxiv.org/abs/1806.03536). First Xu and colleagues test GCNs and GATs on the Citeseer and Cora datasets. They also test adding the Jumping Knowledge Aggregation to the GCN with LSTM, Max pooling and Concatenation aggregation methods. I will also test a simple MLP as a baseline. Xu and colleagues vary the number of layers from 1-6 (using a hidden layer size of 16 or 32) and choose the best performing model on the validation set then compare each of the best models on the test set. When testing I will use 3 different splits to report the mean and standard deviaiton of test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jk_networks import utils, models\n",
    "import torch\n",
    "from itertools import product\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the CiteSeer dataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "citeseer = Planetoid(root='/tmp/CiteSeer', name='CiteSeer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron\n",
    "I will now train a series of MLPs on the citeseer dataset. This should perform worse than the GCN model because it doesn't have any graph level information but it should provide a good baseline for how well a model can do with just the bag of word features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies(model_class,data):\n",
    "  num_layers = range(1, 7)\n",
    "  hidden_layer_size = [16, 32]\n",
    "  val_accuracies = defaultdict(dict)\n",
    "  for num_layers, hidden_layer_size in product(num_layers, hidden_layer_size):\n",
    "    gcn_model = model_class(data.num_features, [hidden_layer_size] * num_layers, data.num_classes)\n",
    "    graph = data[0]\n",
    "    utils.split_data_node_classification(graph, train_ratio=0.6, val_ratio=0.2, manual_seed=42)\n",
    "    utils.train(gcn_model, graph)\n",
    "    model_acc = utils.test(gcn_model, graph, graph.val_mask)\n",
    "    val_accuracies[num_layers][hidden_layer_size] = model_acc\n",
    "  return val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracies = get_accuracies(models.MLP, citeseer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Number of Layers</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hidden Layer Size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.716</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Number of Layers       1      2      3      4      5      6\n",
       "Hidden Layer Size                                          \n",
       "16                 0.710  0.683  0.686  0.638  0.528  0.561\n",
       "32                 0.716  0.720  0.701  0.684  0.531  0.617"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "val_accuracies = pd.DataFrame(val_accuracies)\n",
    "val_accuracies.index.name = 'Hidden Layer Size'\n",
    "val_accuracies.columns.name = 'Number of Layers'\n",
    "val_accuracies.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "As we can see the best result is with the 32 Hidden features, 2 layer model with an accuracy of 72%. Let's retrain 3 times on the train and validation set to see what the test accuracy for the best model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model accuracy: 0.742 ± 0.034\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "best_mlp_model = models.MLP(citeseer.num_features, [32, 32], citeseer.num_classes)\n",
    "def train_best_model(model, data):\n",
    "  graph = data[0]\n",
    "\n",
    "  accuracies = []\n",
    "  for i in range(3):\n",
    "    utils.split_data_node_classification(graph, train_ratio=0.8, val_ratio=0, manual_seed=i)\n",
    "    utils.train(model, graph)\n",
    "    accuracies.append(utils.test(model, graph, graph.test_mask))\n",
    "  accuracies = np.array(accuracies)\n",
    "  return accuracies.mean(), accuracies.std()\n",
    "\n",
    "best_mlp_model_acc, best_mlp_model_std = train_best_model(best_mlp_model, citeseer)\n",
    "\n",
    "print(f'Best model accuracy: {best_mlp_model_acc:.3f} ± {best_mlp_model_std:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Continued\n",
    "The simple MLP model achieves about 74% accuracy on the test set. Let's see if we can imporve this performance by using the graph structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing GCN\n",
    "Following [Xu et al.](https://arxiv.org/abs/1806.03536) I will train a series of GCNs without any Jumping Knowledge on the Citeseer dataset. I will test 12 different models with the number of layers going from 1 to 6 and the number of hidden_feauters in {16, 32}. Note Xu and collegues use a 60, 20, 20 split which is different from the built in split of citesseer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracies = get_accuracies(models.GCN, citeseer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Number of Layers</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hidden Layer Size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.705</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.702</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Number of Layers       1      2      3      4      5      6\n",
       "Hidden Layer Size                                          \n",
       "16                 0.705  0.699  0.684  0.683  0.648  0.639\n",
       "32                 0.702  0.686  0.681  0.671  0.666  0.671"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracies = pd.DataFrame(val_accuracies)\n",
    "val_accuracies.index.name = 'Hidden Layer Size'\n",
    "val_accuracies.columns.name = 'Number of Layers'\n",
    "val_accuracies.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "We can see that the 1 Layer, 32 hidden features network performs the best. I will retrain that model on the validation and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model accuracy: 0.743 ± 0.010\n"
     ]
    }
   ],
   "source": [
    "best_gcn_concat_model = models.GCN(citeseer.num_features, [32], citeseer.num_classes)\n",
    "best_gcn_model_acc, best_gcn_model_std = train_best_model(best_gcn_concat_model, citeseer)\n",
    "print(f'Best model accuracy: {best_gcn_model_acc:.3f} ± {best_gcn_model_std:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Continued\n",
    "As we can seee the normal GCN network is only at about 74% accuracy on the citeseer dataset which is not any better than the mlp model. This number is different from the paper which found a GCN accuracy of 77.3% for the GCN on the citeseer dataset this could be due to some of the [preprocessing](https://github.com/pyg-team/pytorch_geometric/issues/2018) that torch_geometric does to citeseer or because of a different random seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jumping Knowledge GCNs\n",
    "I will now test one of the models proposed in the Xu et al. The jumping knowledge network with gcn layer and the concat aggregation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "class JK_GCN_Concat(models.GCN_JK_Concat):\n",
    "  def __init__(self, starting_features: int, hidden_channels: List[int], output_features: int):\n",
    "    super().__init__(starting_features, hidden_channels, output_features, agg_method='concat')\n",
    "\n",
    "val_accuracies = get_accuracies(JK_GCN_Concat, citeseer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Number of Layers</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hidden Layer Size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.749</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.746</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Number of Layers       1      2      3      4      5      6\n",
       "Hidden Layer Size                                          \n",
       "16                 0.749  0.740  0.725  0.735  0.734  0.740\n",
       "32                 0.746  0.719  0.711  0.713  0.711  0.711"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracies = pd.DataFrame(val_accuracies)\n",
    "val_accuracies.index.name = 'Hidden Layer Size'\n",
    "val_accuracies.columns.name = 'Number of Layers'\n",
    "val_accuracies.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "We can see that the 1 layer 16 hidden features model is the best. So I will retrain it on the validation and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model accuracy: 0.771 ± 0.009\n"
     ]
    }
   ],
   "source": [
    "best_jk_gcn_concat_model = JK_GCN_Concat(citeseer.num_features, [16], citeseer.num_classes)\n",
    "best_jk_gcn_model_acc, best_jk_gcn_model_std = train_best_model(best_jk_gcn_concat_model, citeseer)\n",
    "print(f'Best model accuracy: {best_jk_gcn_model_acc:.3f} ± {best_jk_gcn_model_std:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Continued\n",
    "As we can see the JK-GCN network achieves about 77% accuracy on the citeseer dataset which is better than the mlp model and the standard gcn model. This number is different from the paper which found a GCN accuracy of 78.3% for the jumping gcn on the citeseer dataset. Again this could be due to the different preprocessing."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
